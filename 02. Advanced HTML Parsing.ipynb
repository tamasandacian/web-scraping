{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 02. Advanced HTML Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we will look into how to search for tags by attributes, working with lists of tags, and navigating parse trees.\n",
    "\n",
    "For the purpose of the exercise we will create an example of web scraper that scrapes the page located at http://\n",
    "www.pythonscraping.com/pages/warandpeace.html.\n",
    "\n",
    "In this page the lines spoken by characters in the story are written in red, whereas the names of characters are in green."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the html page\n",
    "html = urlopen('http://www.pythonscraping.com/pages/warandpeace.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create BeautifulSoup object and parse the html content\n",
    "bs = BeautifulSoup(html.read(), 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate the source page for used tags\n",
    "# right click -> View Page Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anna\n",
      "Pavlovna Scherer\n",
      "Empress Marya\n",
      "Fedorovna\n",
      "Prince Vasili Kuragin\n",
      "Anna Pavlovna\n",
      "St. Petersburg\n",
      "the prince\n",
      "Anna Pavlovna\n",
      "Anna Pavlovna\n",
      "the prince\n",
      "the prince\n",
      "the prince\n",
      "Prince Vasili\n",
      "Anna Pavlovna\n",
      "Anna Pavlovna\n",
      "the prince\n",
      "Wintzingerode\n",
      "King of Prussia\n",
      "le Vicomte de Mortemart\n",
      "Montmorencys\n",
      "Rohans\n",
      "Abbe Morio\n",
      "the Emperor\n",
      "the prince\n",
      "Prince Vasili\n",
      "Dowager Empress Marya Fedorovna\n",
      "the baron\n",
      "Anna Pavlovna\n",
      "the Empress\n",
      "the Empress\n",
      "Anna Pavlovna's\n",
      "Her Majesty\n",
      "Baron\n",
      "Funke\n",
      "The prince\n",
      "Anna\n",
      "Pavlovna\n",
      "the Empress\n",
      "The prince\n",
      "Anatole\n",
      "the prince\n",
      "The prince\n",
      "Anna\n",
      "Pavlovna\n",
      "Anna Pavlovna\n"
     ]
    }
   ],
   "source": [
    "# looking at the span tags we can see that some of them have CSS style (e.g. green, red)\n",
    "# we can grab all the names from span green color\n",
    "namelist = bs.find_all('span', {'class': 'green'})\n",
    "for name in namelist:\n",
    "    # to get only the text from spans we use get_text() function\n",
    "    print(name.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find() and find_all() with BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_tags = bs.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h1>War and Peace</h1>, <h2>Chapter 1</h2>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_spans = bs.find_all('span', {'class': {'green', 'red'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"red\">Well, Prince, so Genoa and Lucca are now just family estates of the\n",
       " Buonapartes. But I warn you, if you don't tell me that this means war,\n",
       " if you still try to defend the infamies and horrors perpetrated by\n",
       " that Antichrist- I really believe he is Antichrist- I will have\n",
       " nothing more to do with you and you are no longer my friend, no longer\n",
       " my 'faithful slave,' as you call yourself! But how do you do? I see\n",
       " I have frightened you- sit down and tell me all the news.</span>,\n",
       " <span class=\"green\">Anna\n",
       " Pavlovna Scherer</span>,\n",
       " <span class=\"green\">Empress Marya\n",
       " Fedorovna</span>,\n",
       " <span class=\"green\">Prince Vasili Kuragin</span>,\n",
       " <span class=\"green\">Anna Pavlovna</span>,\n",
       " <span class=\"green\">St. Petersburg</span>,\n",
       " <span class=\"red\">If you have nothing better to do, Count [or Prince], and if the\n",
       " prospect of spending an evening with a poor invalid is not too\n",
       " terrible, I shall be very charmed to see you tonight between 7 and 10-\n",
       " Annette Scherer.</span>,\n",
       " <span class=\"red\">Heavens! what a virulent attack!</span>,\n",
       " <span class=\"green\">the prince</span>,\n",
       " <span class=\"green\">Anna Pavlovna</span>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 10 spans containing both colors: green, red\n",
    "all_spans[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# if we want to find the number of times \"the prince\" is surrounded by tags on the example page\n",
    "# we could replace our function .find_all()\n",
    "namelist = bs.find_all(text='the prince')\n",
    "print(len(namelist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The limit argument is used only in the find_all method; find is equivalent to the same find_all with a limit of 1. However, if we are interested only in retrieving the first x items from the page, we could specify the limit in the limit argument of the function. This will give us the first items on the page in the order that they occur but not necessarily the first ones we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# the following two lines are identical:\n",
    "# bs.find_all('', {'id': 'text'})\n",
    "# bs.find_all(id='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following line will throw an error because class will make reference to Python class and not CSS class of a tag\n",
    "# bs.find_all(class='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"green\">Anna\n",
       " Pavlovna Scherer</span>, <span class=\"green\">Empress Marya\n",
       " Fedorovna</span>, <span class=\"green\">Prince Vasili Kuragin</span>, <span class=\"green\">Anna Pavlovna</span>, <span class=\"green\">St. Petersburg</span>, <span class=\"green\">the prince</span>, <span class=\"green\">Anna Pavlovna</span>, <span class=\"green\">Anna Pavlovna</span>, <span class=\"green\">the prince</span>, <span class=\"green\">the prince</span>, <span class=\"green\">the prince</span>, <span class=\"green\">Prince Vasili</span>, <span class=\"green\">Anna Pavlovna</span>, <span class=\"green\">Anna Pavlovna</span>, <span class=\"green\">the prince</span>, <span class=\"green\">Wintzingerode</span>, <span class=\"green\">King of Prussia</span>, <span class=\"green\">le Vicomte de Mortemart</span>, <span class=\"green\">Montmorencys</span>, <span class=\"green\">Rohans</span>, <span class=\"green\">Abbe Morio</span>, <span class=\"green\">the Emperor</span>, <span class=\"green\">the prince</span>, <span class=\"green\">Prince Vasili</span>, <span class=\"green\">Dowager Empress Marya Fedorovna</span>, <span class=\"green\">the baron</span>, <span class=\"green\">Anna Pavlovna</span>, <span class=\"green\">the Empress</span>, <span class=\"green\">the Empress</span>, <span class=\"green\">Anna Pavlovna's</span>, <span class=\"green\">Her Majesty</span>, <span class=\"green\">Baron\n",
       " Funke</span>, <span class=\"green\">The prince</span>, <span class=\"green\">Anna\n",
       " Pavlovna</span>, <span class=\"green\">the Empress</span>, <span class=\"green\">The prince</span>, <span class=\"green\">Anatole</span>, <span class=\"green\">the prince</span>, <span class=\"green\">The prince</span>, <span class=\"green\">Anna\n",
       " Pavlovna</span>, <span class=\"green\">Anna Pavlovna</span>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to overcome this issue we can use the following line of code:\n",
    "bs.find_all('', {'class': 'green'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with children and other descendants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we will focus the url page http://www.pythonscraping.com/pages/page3.html  where we learn how to discern or differentiate the childrens and descendants in the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the html page\n",
    "html = urlopen('http://www.pythonscraping.com/pages/page3.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the html page using BeautifulSoup\n",
    "bs = BeautifulSoup(html.read(), 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift1\"><td>\n",
      "Vegetable Basket\n",
      "</td><td>\n",
      "This vegetable basket is the perfect gift for your health conscious (or overweight) friends!\n",
      "<span class=\"excitingNote\">Now with super-colorful bell peppers!</span>\n",
      "</td><td>\n",
      "$15.00\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img1.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift2\"><td>\n",
      "Russian Nesting Dolls\n",
      "</td><td>\n",
      "Hand-painted by trained monkeys, these exquisite dolls are priceless! And by \"priceless,\" we mean \"extremely expensive\"! <span class=\"excitingNote\">8 entire dolls per set! Octuple the presents!</span>\n",
      "</td><td>\n",
      "$10,000.52\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img2.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift3\"><td>\n",
      "Fish Painting\n",
      "</td><td>\n",
      "If something seems fishy about this painting, it's because it's a fish! <span class=\"excitingNote\">Also hand-painted by trained monkeys!</span>\n",
      "</td><td>\n",
      "$10,005.00\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img3.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift4\"><td>\n",
      "Dead Parrot\n",
      "</td><td>\n",
      "This is an ex-parrot! <span class=\"excitingNote\">Or maybe he's only resting?</span>\n",
      "</td><td>\n",
      "$0.50\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img4.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift5\"><td>\n",
      "Mystery Box\n",
      "</td><td>\n",
      "If you love suprises, this mystery box is for you! Do not place on light-colored surfaces. May cause oil staining. <span class=\"excitingNote\">Keep your friends guessing!</span>\n",
      "</td><td>\n",
      "$1.50\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img6.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the siblings from table\n",
    "for sibling in bs.find('table', {'id':'giftList'}).tr.next_siblings:\n",
    "    print(sibling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this code is to print all rows of products from the product table, except the header of the table. The reason is that objects cannot be siblings with themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tr><th>\n",
       "Item Title\n",
       "</th><th>\n",
       "Description\n",
       "</th><th>\n",
       "Cost\n",
       "</th><th>\n",
       "Image\n",
       "</th></tr>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the first row of the table (header)\n",
    "bs.find('table', {'id': 'giftList'}).tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with parents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When scraping pages, we will likely discover that we need to find parents of tags less frequently than to find their children or siblings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get html page\n",
    "html = urlopen('http://www.pythonscraping.com/pages/page3.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the html page using BeautifulSoup\n",
    "bs = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "$15.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bs.find('img', {'src': '../img/gifts/img1.jpg'}).parent.previous_sibling.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "$15.00\n",
      "\n",
      "\n",
      "This vegetable basket is the perfect gift for your health conscious (or overweight) friends!\n",
      "Now with super-colorful bell peppers!\n",
      "\n",
      "\n",
      "Vegetable Basket\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the previous siblings of the td tag which is parent in this case\n",
    "# we use .get_text() function to retrive the text of all siblings\n",
    "for sibling in bs.find('img', {'src': '../img/gifts/img1.jpg'}).parent.previous_siblings:\n",
    "    print(sibling.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Expressions and BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume that we want to extract image urls from an html page. At first we could just grab all the images using .find_all(\"img\") function, but there is a problem. \n",
    "\n",
    "In addition to the extra images such as logos, modern websites often have hidden images, blank images used for spacing and aligning elements that we are not aware of. The solution is to look for a tag itself such as the file path of the product images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the html page\n",
    "html = urlopen('http://www.pythonscraping.com/pages/page3.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the html page using BeautifulSoup\n",
    "bs = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract images\n",
    "images = bs.find_all('img', {'src': re.compile('\\.\\.\\/img/gifts/img.*\\.jpg')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../img/gifts/img1.jpg\n",
      "../img/gifts/img2.jpg\n",
      "../img/gifts/img3.jpg\n",
      "../img/gifts/img4.jpg\n",
      "../img/gifts/img6.jpg\n"
     ]
    }
   ],
   "source": [
    "for image in images:\n",
    "    print(image['src'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
